{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jainam/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,render=0,q=[]):\n",
    "\n",
    "        if(render==0):\n",
    "            self.env = gym.make(\"MountainCar-v0\")\n",
    "        else:\n",
    "            self.env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "        self.env.reset()\n",
    "        self.num_pos_states=5\n",
    "        self.num_vel_states=5\n",
    "\n",
    "        self.pos_range=[-1.2,0.6]\n",
    "        self.vel_range=[-0.07,0.07]\n",
    "\n",
    "        self.num_actions=self.env.action_space.n\n",
    "        self.num_states=self.num_pos_states*self.num_vel_states\n",
    "        if(len(q)==0):\n",
    "            self.action_value=np.random.normal(size=(self.num_states, self.num_actions), loc=0.5, scale=0.001)\n",
    "        else:\n",
    "            self.action_value=q\n",
    "        self.num_episodes=1000\n",
    "        self.num_steps=100\n",
    "        self.alpha=0.001\n",
    "        self.gamma=0.9\n",
    "        self.reward_array=[]\n",
    "        self.epsilon=0.1\n",
    "\n",
    "\n",
    "    def find_state(self, value, ranges, num_partitions):\n",
    "        x=ranges[0]\n",
    "        y=ranges[1]\n",
    "        k=num_partitions\n",
    "        inc=float(-x+y)/k\n",
    "        for i in range(k):\n",
    "            if value>=inc*i+x and value<inc*(i+1)+x:\n",
    "                return i\n",
    "            \n",
    "        if value<x: return 0\n",
    "        if value>=y: return k-1\n",
    "\n",
    "    def find_final_state(self, value):\n",
    "        pos_state=int(self.find_state(value[0], self.pos_range, self.num_pos_states))\n",
    "        vel_state=int(self.find_state(value[1], self.vel_range, self.num_vel_states))\n",
    "\n",
    "        return pos_state+self.num_pos_states*vel_state\n",
    "\n",
    "            \n",
    "    def epsilon_greedy(self,state):\n",
    "        action_greedy=np.argmax(self.action_value[state])\n",
    "        action_array=np.arange(self.num_actions)\n",
    "        action_array=np.insert(action_array,0,action_greedy)\n",
    "        prob_array=np.ones(self.num_actions)*self.epsilon/self.num_actions\n",
    "        prob_array=np.insert(prob_array,0,1-self.epsilon)\n",
    "        action_actual=np.random.choice(a=action_array, p=prob_array)\n",
    "        return action_actual\n",
    "\n",
    "\n",
    "    def episode_iter(self):\n",
    "        curr_state=self.find_final_state(self.env.reset()[0])\n",
    "        state_action_reward_array=[]\n",
    "        cum_reward=0\n",
    "        while(True):\n",
    "            action=self.epsilon_greedy(curr_state)\n",
    "            observation, reward, terminated, truncated, _=self.env.step(action)\n",
    "            state_action_reward_array.append([curr_state, action, reward])\n",
    "            curr_state=self.find_final_state(observation)\n",
    "            cum_reward+=reward\n",
    "            if(terminated or truncated):\n",
    "                print(f'total reward is {cum_reward}')\n",
    "                self.reward_array.append(cum_reward)\n",
    "                return state_action_reward_array\n",
    "            \n",
    "    def SARSA_L(self):\n",
    "        E=np.zeros((self.num_states, self.num_actions))\n",
    "        for ne in range(self.num_episodes):\n",
    "            raw_state=self.env.reset()[0]\n",
    "            curr_state=self.find_final_state(raw_state)\n",
    "            cum_reward=0\n",
    "            action=self.epsilon_greedy(curr_state)\n",
    "            for ns in range(self.num_steps):\n",
    "                observation, reward, terminated, truncated, _=self.env.step(action)\n",
    "                # print(reward)\n",
    "                next_state=self.find_final_state(observation)\n",
    "                next_action=self.epsilon_greedy(next_state)\n",
    "                delta=reward+self.gamma*self.action_value[next_state,next_action]-self.action_value[curr_state,action]\n",
    "                E[curr_state, action]+=1\n",
    "                for s in range(self.num_states):\n",
    "                    for a in range(self.num_actions):\n",
    "                        self.action_value[s,a]+=self.alpha*delta*E[s,a]\n",
    "                        E[s,a]=self.gamma*delta*E[s,a]\n",
    "                curr_state=next_state\n",
    "                action=next_action\n",
    "                cum_reward+=reward\n",
    "                # print(f'Car is in state {curr_state} at step {ns} of episode {ne}')\n",
    "                if terminated or truncated: \n",
    "                    print(\"hi\")\n",
    "                    self.reward_array.append(cum_reward)\n",
    "                    print(cum_reward)\n",
    "                    break\n",
    "\n",
    "    def TD0(self):\n",
    "        for ne in range(self.num_episodes):\n",
    "            curr_state=self.find_final_state(self.env.reset()[0])\n",
    "            cum_reward=0\n",
    "            action=self.epsilon_greedy(curr_state)\n",
    "            for ns in range(self.num_steps):\n",
    "                observation, reward, terminated, truncated, _=self.env.step(action)\n",
    "                # print(reward)\n",
    "                next_state=self.find_final_state(observation)\n",
    "                next_action=self.epsilon_greedy(next_state)\n",
    "                self.action_value[curr_state,action]+=self.alpha*(reward+self.gamma*self.action_value[next_state,next_action]-self.action_value[curr_state,action])\n",
    "                curr_state=next_state\n",
    "                action=next_action\n",
    "                cum_reward+=reward\n",
    "                # print(f'Car is in state {next_state} at step {ns} of episode {ne}')\n",
    "                if terminated or truncated: \n",
    "                    print(\"hi\")\n",
    "                    self.reward_array.append(cum_reward)\n",
    "                    break\n",
    "\n",
    "    \n",
    "    def MonteCarlo(self):\n",
    "        for _ in range(self.num_episodes):\n",
    "\n",
    "            reward_array=self.episode_iter()\n",
    "            n=len(reward_array)\n",
    "            Gt=np.zeros(n)\n",
    "            Gt[n-1]=reward_array[n-1][2]\n",
    "            for i in range(n-2,-1,-1):\n",
    "                Gt[i]=reward_array[i][2]+self.gamma*Gt[i+1]\n",
    "\n",
    "            for i,(state,action,_) in enumerate(reward_array):\n",
    "                self.action_value[state,action]+=self.alpha*(Gt[i]-self.action_value[state,action])\n",
    "\n",
    "\n",
    "    def graph_plotter(self):\n",
    "        time=np.arange(len(self.reward_array))\n",
    "        plt.plot(time,self.reward_array)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deterministic_Agent():\n",
    "    def __init__(self, render=0, q=[]):\n",
    "        if(render==0):\n",
    "            self.env = gym.make(\"MountainCar-v0\")\n",
    "        else:\n",
    "            self.env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "        self.env.reset()\n",
    "\n",
    "        self.num_pos_states=5\n",
    "        self.num_vel_states=5\n",
    "\n",
    "        self.pos_range=[-1.2,0.6]\n",
    "        self.vel_range=[-0.07,0.07]\n",
    "\n",
    "        self.num_actions=self.env.action_space.n\n",
    "        self.num_states=self.num_pos_states*self.num_vel_states\n",
    "        if(len(q)==0):\n",
    "            self.state_value=np.random.normal(size=self.num_states, loc=0.5, scale=0.001)\n",
    "        else:\n",
    "            self.state_value=q\n",
    "\n",
    "    def find_state(self, value, ranges, num_partitions):\n",
    "        x=ranges[0]\n",
    "        y=ranges[1]\n",
    "        k=num_partitions\n",
    "        inc=float(-x+y)/k\n",
    "        for i in range(k):\n",
    "            if value>=inc*i+x and value<inc*(i+1)+x:\n",
    "                return i\n",
    "            \n",
    "        if value<x: return 0\n",
    "        if value>=y: return k-1\n",
    "\n",
    "    def find_final_state(self, value):\n",
    "        pos_state=int(self.find_state(value[0], self.pos_range, self.num_pos_states))\n",
    "        vel_state=int(self.find_state(value[1], self.vel_range, self.num_vel_states))\n",
    "\n",
    "        return pos_state+self.num_pos_states*vel_state\n",
    "    \n",
    "    def greedy(self, curr_state):\n",
    "        pass\n",
    "\n",
    "    def episode_iter(self):\n",
    "        curr_state=self.find_final_state(self.env.reset()[0])\n",
    "        cum_reward=0\n",
    "        while(True):\n",
    "            action=self.greedy(curr_state)\n",
    "            observation, reward, terminated, truncated, _=self.env.step(action)\n",
    "            curr_state=self.find_final_state(observation)\n",
    "            cum_reward+=reward\n",
    "            if(terminated or truncated):\n",
    "                self.reward_array.append(cum_reward)\n",
    "                return\n",
    "\n",
    "    def Value_Iteration(self):\n",
    "        for action in range(self.num_actions):\n",
    "            observation, reward, terminated, truncated, _=self.env.step(action)\n",
    "            next_state=self.find_final_state(observation)\n",
    "            cost=reward+self.state_value[next_state]\n",
    "            if cost>max_cost:\n",
    "                max_cost=cost\n",
    "\n",
    "    def graph_plotter(self):\n",
    "        time=np.arange(len(self.reward_array))\n",
    "        plt.plot(time,self.reward_array)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6126/2850444683.py:89: RuntimeWarning: overflow encountered in double_scalars\n",
      "  self.action_value[s,a]+=self.alpha*delta*E[s,a]\n",
      "/tmp/ipykernel_6126/2850444683.py:90: RuntimeWarning: overflow encountered in double_scalars\n",
      "  E[s,a]=self.gamma*delta*E[s,a]\n",
      "/tmp/ipykernel_6126/2850444683.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta=reward+self.gamma*self.action_value[next_state,next_action]-self.action_value[curr_state,action]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent1=Agent(render=0)\n",
    "agent1.SARSA_L()\n",
    "agent1.env.close()\n",
    "agent1.graph_plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49196078  0.486134    0.49826975]\n",
      " [ 0.2769896   0.30677853  0.3122845 ]\n",
      " [ 0.40717175  0.39376757  0.35892286]\n",
      " [ 0.50043682  0.49926343  0.50066649]\n",
      " [ 0.49987484  0.49898563  0.50002079]\n",
      " [-0.06806306 -0.07307773 -0.07064828]\n",
      " [-5.57672949 -5.45852981 -5.4299597 ]\n",
      " [-2.57829286 -2.57277929 -2.59645555]\n",
      " [ 0.26961093  0.27396188  0.27576461]\n",
      " [ 0.50010851  0.49828987  0.49854303]\n",
      " [-1.52455427 -1.2099007  -1.31863678]\n",
      " [-9.62886284 -9.46783461 -9.60102222]\n",
      " [-9.61631128 -9.6587492  -9.62801618]\n",
      " [-0.45384616 -0.40048653 -0.40071304]\n",
      " [ 0.490659    0.3732173   0.49931218]\n",
      " [ 0.15015208  0.19863158  0.17380118]\n",
      " [-5.12188204 -4.94561191 -4.99808776]\n",
      " [-3.44950206 -3.47472819 -3.43005897]\n",
      " [ 0.14309452  0.13822489  0.07994083]\n",
      " [ 0.49851809  0.48979374  0.48025766]\n",
      " [ 0.49958296  0.49985139  0.49960988]\n",
      " [ 0.36525174  0.41629233  0.37754547]\n",
      " [ 0.417602    0.39531273  0.37371523]\n",
      " [ 0.50071053  0.50055924  0.49927281]\n",
      " [ 0.49792078  0.50036432  0.49998659]]\n"
     ]
    }
   ],
   "source": [
    "print(agent1.action_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward is -200.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[12, 0, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 2, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [11, 1, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0],\n",
       " [12, 0, -1.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2=Agent(render=1, q=agent1.action_value)\n",
    "agent2.episode_iter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
